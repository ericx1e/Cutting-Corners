{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6d4580-6a83-4118-80fe-a970859afc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d4d3df-5442-47f0-8cfd-33901ccc1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane = np.load('data/airplane.npy')\n",
    "car = np.load('data/car.npy')\n",
    "dragon = np.load('data/dragon.npy')\n",
    "crocodile = np.load('data/crocodile.npy')\n",
    "computer = np.load('data/computer.npy')\n",
    "elephant = np.load('data/elephant.npy')\n",
    "flower = np.load('data/flower.npy')\n",
    "guitar = np.load('data/guitar.npy')\n",
    "hamburger = np.load('data/hamburger.npy')\n",
    "helicopter = np.load('data/helicopter.npy')\n",
    "house = np.load('data/house.npy')\n",
    "hurricane = np.load('data/hurricane.npy')\n",
    "jail = np.load('data/jail.npy')\n",
    "keyboard = np.load('data/keyboard.npy')\n",
    "leaf = np.load('data/leaf.npy')\n",
    "mermaid = np.load('data/mermaid.npy')\n",
    "microwave = np.load('data/microwave.npy')\n",
    "monkey = np.load('data/monkey.npy')\n",
    "pants = np.load('data/pants.npy')\n",
    "broccoli = np.load('data/broccoli.npy')\n",
    "brain = np.load('data/brain.npy')\n",
    "raccoon = np.load('data/raccoon.npy')\n",
    "radio = np.load('data/radio.npy')\n",
    "rifle = np.load('data/rifle.npy')\n",
    "sink = np.load('data/sink.npy')\n",
    "\n",
    "airplane = airplane[:1000, :]\n",
    "car = car[:1000, :]\n",
    "dragon = dragon[:1000, :]\n",
    "crocodile = crocodile[:1000, :]\n",
    "computer = computer[:1000, :]\n",
    "elephant = elephant[:1000, :]\n",
    "flower = flower[:1000, :]\n",
    "guitar = guitar[:1000, :]\n",
    "hamburger = hamburger[:1000, :]\n",
    "helicopter = helicopter[:1000, :]\n",
    "house = house[:1000, :]\n",
    "hurricane = hurricane[:1000, :]\n",
    "jail = jail[:1000, :]\n",
    "keyboard = keyboard[:1000, :]\n",
    "leaf = leaf[:1000, :]\n",
    "mermaid = mermaid[:1000, :]\n",
    "microwave = microwave[:1000, :]\n",
    "monkey = monkey[:1000, :]\n",
    "pants = pants[:1000, :]\n",
    "broccoli = broccoli[:1000, :]\n",
    "brain = brain[:1000, :]\n",
    "raccoon = raccoon[:1000, :]\n",
    "radio = radio[:1000, :]\n",
    "rifle = rifle[:1000, :]\n",
    "sink = sink[:1000, :]\n",
    "\n",
    "labels = ['airplane', 'car', 'dragon', 'crocodile', 'computer', 'elephant', 'flower', 'guitar', 'hamburger',\n",
    "               'helicopter', 'house', 'hurricane', 'jail', 'keyboard', 'leaf', 'mermaid', 'microwave', 'monkey',\n",
    "               'pants', 'broccoli', 'brain', 'raccoon', 'radio', 'rifle', 'sink']\n",
    "label_arrs = [airplane, car, dragon, crocodile, computer, elephant, flower, guitar, hamburger, helicopter,\n",
    "                   house, hurricane, jail, keyboard, leaf, mermaid, microwave, monkey, pants, broccoli, brain,\n",
    "                   raccoon, radio, rifle, sink]\n",
    "\n",
    "encoding = {\n",
    "    'airplane': 0,\n",
    "    'car': 1,\n",
    "    'dragon': 2,\n",
    "    'crocodile': 3,\n",
    "    'computer': 4,\n",
    "    'elephant': 5,\n",
    "    'flower': 6,\n",
    "    'guitar': 7,\n",
    "    'hamburger': 8,\n",
    "    'helicopter': 9,\n",
    "    'house': 10,\n",
    "    'hurricane': 11,\n",
    "    'jail': 12,\n",
    "    'keyboard': 13,\n",
    "    'leaf': 14,\n",
    "    'mermaid': 15,\n",
    "    'microwave': 16,\n",
    "    'monkey': 17,\n",
    "    'pants': 18,\n",
    "    'broccoli': 19,\n",
    "    'brain': 20,\n",
    "    'raccoon': 21,\n",
    "    'radio': 22,\n",
    "    'rifle': 23,\n",
    "    'sink': 24\n",
    "}\n",
    "\n",
    "reversed_encoding = {\n",
    "    0: 'airplane',\n",
    "    1: 'car',\n",
    "    2: 'dragon',\n",
    "    3: 'crocodile',\n",
    "    4: 'computer',\n",
    "    5: 'elephant',\n",
    "    6: 'flower',\n",
    "    7: 'guitar',\n",
    "    8: 'hamburger',\n",
    "    9: 'helicopter',\n",
    "    10: 'house',\n",
    "    11: 'hurricane',\n",
    "    12: 'jail',\n",
    "    13: 'keyboard',\n",
    "    14: 'leaf',\n",
    "    15: 'mermaid',\n",
    "    16: 'microwave',\n",
    "    17: 'monkey',\n",
    "    18: 'pants',\n",
    "    19: 'broccoli',\n",
    "    20: 'brain',\n",
    "    21: 'raccoon',\n",
    "    22: 'radio',\n",
    "    23: 'rifle',\n",
    "    24: 'sink'\n",
    "}\n",
    "\n",
    "datapts = []\n",
    "\n",
    "for label, arr in zip(labels, label_arrs):\n",
    "    for row in arr:\n",
    "        datapts.append({'image': row, 'label': label})\n",
    "\n",
    "all_data = pd.DataFrame(datapts)\n",
    "all_data['label'] = all_data['label'].apply(lambda x : encoding[x])\n",
    "\n",
    "def plot_image(img):\n",
    "    img = torch.reshape(img, (28, 28))\n",
    "    plt.show(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05b6c16-e329-4e6c-8b9a-e2c88a28f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = \n",
    "#load dataset into dataloader, etc\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)  # Reset indices to ensure contiguity\n",
    "        self.images, self.labels = self.dataframe['image'], self.dataframe['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        img = img.reshape((28,28))\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)\n",
    "            \n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "# Assuming you have defined your DataFrame 'all_data' somewhere\n",
    "shuffled_df = all_data.sample(frac=1, random_state=42)\n",
    "\n",
    "total_rows = len(shuffled_df)\n",
    "train_rows = int(0.7 * total_rows)\n",
    "val_rows = int(0.1 * total_rows)\n",
    "\n",
    "train_df = shuffled_df[:train_rows]\n",
    "val_df = shuffled_df[train_rows:train_rows + val_rows]\n",
    "test_df = shuffled_df[train_rows + val_rows:]\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_dataset = SketchDataset(train_df)\n",
    "val_dataset = SketchDataset(val_df)\n",
    "test_dataset = SketchDataset(test_df)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291b339c-55f5-43c0-8058-99f3437f2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        #goal: simplified Alexnet architecture\n",
    "        #input: 28x28x1 image, grayscaled\n",
    "        #first idea: 3 conv-relu-pool layers, followed by 2 fc layers and softmax non-linearity\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, 3, 1, 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(10, 20, 3, 1, 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )     \n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(980, 980),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = .2),\n",
    "            nn.Linear(980, 25)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        return self.linear_layers(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = torch.reshape(x, (1, 1, 28, 28))\n",
    "        output = self.forward(x)\n",
    "        return reversed_encoding[torch.argmax(output, dim=1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08982060-629e-4659-9482-ab9823ed8a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 1.910865331547601 Train Acc: 0.5205142857142857 Val Loss: 1.1555224132537842 Val Acc: 0.6776\n",
      "Epoch: 1 Train Loss: 1.0921112829446793 Train Acc: 0.6892571428571429 Val Loss: 1.0035794186592102 Val Acc: 0.7112\n",
      "Epoch: 2 Train Loss: 0.9652575765337262 Train Acc: 0.7285714285714285 Val Loss: 0.9386996173858643 Val Acc: 0.7316\n",
      "Epoch: 3 Train Loss: 0.9130288348879133 Train Acc: 0.7405714285714285 Val Loss: 0.9031363570690155 Val Acc: 0.7428\n",
      "Epoch: 4 Train Loss: 0.8787153197186334 Train Acc: 0.7472 Val Loss: 0.9107001161575318 Val Acc: 0.7396\n",
      "Epoch: 5 Train Loss: 0.8444904925142016 Train Acc: 0.7630285714285714 Val Loss: 0.9005841755867005 Val Acc: 0.7464\n",
      "Epoch: 6 Train Loss: 0.8333063973699297 Train Acc: 0.7632571428571429 Val Loss: 0.8711510789394379 Val Acc: 0.7592\n",
      "Epoch: 7 Train Loss: 0.8104812551396233 Train Acc: 0.77 Val Loss: 0.8285165238380432 Val Acc: 0.7704\n",
      "Epoch: 8 Train Loss: 0.7994597965478897 Train Acc: 0.7754285714285715 Val Loss: 0.8328259384632111 Val Acc: 0.7616\n",
      "Epoch: 9 Train Loss: 0.7889000595467431 Train Acc: 0.7785142857142857 Val Loss: 0.8228111249208451 Val Acc: 0.7688\n",
      "Epoch: 10 Train Loss: 0.7805747955186026 Train Acc: 0.7791428571428571 Val Loss: 0.8273119461536408 Val Acc: 0.7692\n",
      "Epoch: 11 Train Loss: 0.7632561337947845 Train Acc: 0.7814285714285715 Val Loss: 0.8195977503061295 Val Acc: 0.7688\n",
      "Epoch: 12 Train Loss: 0.7535953366756439 Train Acc: 0.7866857142857143 Val Loss: 0.7969654989242554 Val Acc: 0.776\n",
      "Epoch: 13 Train Loss: 0.7417786699533463 Train Acc: 0.7912571428571429 Val Loss: 0.803706169128418 Val Acc: 0.7756\n",
      "Epoch: 14 Train Loss: 0.7292158278397152 Train Acc: 0.7913142857142857 Val Loss: 0.7919850426912308 Val Acc: 0.7772\n",
      "Epoch: 15 Train Loss: 0.7200252571276256 Train Acc: 0.7974285714285714 Val Loss: 0.776010856628418 Val Acc: 0.7808\n",
      "Epoch: 16 Train Loss: 0.7088270594392504 Train Acc: 0.8008 Val Loss: 0.7810658383369445 Val Acc: 0.7812\n",
      "Epoch: 17 Train Loss: 0.6975248607567378 Train Acc: 0.8041142857142857 Val Loss: 0.7601151025295257 Val Acc: 0.7832\n",
      "Epoch: 18 Train Loss: 0.6903223557557379 Train Acc: 0.8070857142857143 Val Loss: 0.7744654512405396 Val Acc: 0.7772\n",
      "Epoch: 19 Train Loss: 0.6811464903184345 Train Acc: 0.8096 Val Loss: 0.7529565733671189 Val Acc: 0.7844\n",
      "Epoch: 20 Train Loss: 0.6700184774398804 Train Acc: 0.8132571428571429 Val Loss: 0.7404205691814423 Val Acc: 0.7896\n",
      "Epoch: 21 Train Loss: 0.6584997251204082 Train Acc: 0.8148571428571428 Val Loss: 0.7423705750703812 Val Acc: 0.7852\n",
      "Epoch: 22 Train Loss: 0.6480186803851808 Train Acc: 0.8178285714285715 Val Loss: 0.7539252859354019 Val Acc: 0.782\n",
      "Epoch: 23 Train Loss: 0.6382866263389587 Train Acc: 0.8246857142857142 Val Loss: 0.7365793776512146 Val Acc: 0.7896\n",
      "Epoch: 24 Train Loss: 0.6316245389836175 Train Acc: 0.8233714285714285 Val Loss: 0.7552409768104553 Val Acc: 0.7884\n",
      "Epoch: 25 Train Loss: 0.618657317331859 Train Acc: 0.8313714285714285 Val Loss: 0.7209988182783127 Val Acc: 0.7956\n",
      "Epoch: 26 Train Loss: 0.6125034808261054 Train Acc: 0.8290857142857143 Val Loss: 0.7361326515674591 Val Acc: 0.7932\n",
      "Epoch: 27 Train Loss: 0.6055002581221717 Train Acc: 0.8305714285714285 Val Loss: 0.731693377494812 Val Acc: 0.7908\n",
      "Epoch: 28 Train Loss: 0.5995213799817222 Train Acc: 0.8328 Val Loss: 0.741660760641098 Val Acc: 0.79\n",
      "Epoch: 29 Train Loss: 0.5877749695948192 Train Acc: 0.8366285714285714 Val Loss: 0.7160964500904083 Val Acc: 0.7896\n",
      "Epoch: 30 Train Loss: 0.5837880663360868 Train Acc: 0.8398285714285715 Val Loss: 0.7036128306388855 Val Acc: 0.8048\n",
      "Epoch: 31 Train Loss: 0.5739427305970873 Train Acc: 0.8426285714285714 Val Loss: 0.7017508268356323 Val Acc: 0.8056\n",
      "Epoch: 32 Train Loss: 0.5720677323852267 Train Acc: 0.8411428571428572 Val Loss: 0.709184308052063 Val Acc: 0.8028\n",
      "Epoch: 33 Train Loss: 0.5636540976592472 Train Acc: 0.8456571428571429 Val Loss: 0.700733323097229 Val Acc: 0.8036\n",
      "Epoch: 34 Train Loss: 0.5553069347568921 Train Acc: 0.8468571428571429 Val Loss: 0.7129624265432358 Val Acc: 0.7992\n",
      "Epoch: 35 Train Loss: 0.5502167384113584 Train Acc: 0.8518857142857142 Val Loss: 0.7064441937208176 Val Acc: 0.7968\n",
      "Epoch: 36 Train Loss: 0.5419650107196399 Train Acc: 0.8508571428571429 Val Loss: 0.7004751253128052 Val Acc: 0.8016\n",
      "Epoch: 37 Train Loss: 0.5369799303156989 Train Acc: 0.8525142857142857 Val Loss: 0.6936641156673431 Val Acc: 0.8036\n",
      "Epoch: 38 Train Loss: 0.5331523154888834 Train Acc: 0.8557714285714285 Val Loss: 0.6960354673862458 Val Acc: 0.8056\n",
      "Epoch: 39 Train Loss: 0.5264461254222053 Train Acc: 0.8574285714285714 Val Loss: 0.6952582520246505 Val Acc: 0.808\n",
      "Epoch: 40 Train Loss: 0.5220534327200481 Train Acc: 0.8602285714285715 Val Loss: 0.6954002499580383 Val Acc: 0.796\n",
      "Epoch: 41 Train Loss: 0.5137932638611112 Train Acc: 0.8628 Val Loss: 0.6918242341279983 Val Acc: 0.8048\n",
      "Epoch: 42 Train Loss: 0.5082109299727848 Train Acc: 0.8642285714285715 Val Loss: 0.6929638195037842 Val Acc: 0.8024\n",
      "Epoch: 43 Train Loss: 0.5040797332780702 Train Acc: 0.8654285714285714 Val Loss: 0.6819627064466477 Val Acc: 0.8064\n",
      "Epoch: 44 Train Loss: 0.49668123126029967 Train Acc: 0.868 Val Loss: 0.6890554320812226 Val Acc: 0.804\n",
      "Epoch: 45 Train Loss: 0.49380758498396193 Train Acc: 0.8684571428571428 Val Loss: 0.689568510055542 Val Acc: 0.8032\n",
      "Epoch: 46 Train Loss: 0.4905632349423 Train Acc: 0.8674857142857143 Val Loss: 0.6905352294445037 Val Acc: 0.804\n",
      "Epoch: 47 Train Loss: 0.4880591962167195 Train Acc: 0.8685714285714285 Val Loss: 0.681355015039444 Val Acc: 0.8064\n",
      "Epoch: 48 Train Loss: 0.4831879737121718 Train Acc: 0.8718857142857143 Val Loss: 0.678400884270668 Val Acc: 0.8084\n",
      "Epoch: 49 Train Loss: 0.47658783469881333 Train Acc: 0.876 Val Loss: 0.6784937316179276 Val Acc: 0.8068\n",
      "Epoch: 50 Train Loss: 0.4742678099019187 Train Acc: 0.8752571428571428 Val Loss: 0.6909870457649231 Val Acc: 0.8012\n",
      "Epoch: 51 Train Loss: 0.46909952895981927 Train Acc: 0.8765142857142857 Val Loss: 0.6773633301258087 Val Acc: 0.8072\n",
      "Epoch: 52 Train Loss: 0.46305284704480854 Train Acc: 0.8796 Val Loss: 0.6812916597723961 Val Acc: 0.808\n",
      "Epoch: 53 Train Loss: 0.4631225296003478 Train Acc: 0.8801714285714286 Val Loss: 0.6753909158706665 Val Acc: 0.8076\n",
      "Epoch: 54 Train Loss: 0.45662659900529046 Train Acc: 0.8824 Val Loss: 0.6773426616191864 Val Acc: 0.8048\n",
      "Epoch: 55 Train Loss: 0.4582091152242252 Train Acc: 0.8802857142857143 Val Loss: 0.6832466518878937 Val Acc: 0.8044\n",
      "Epoch: 56 Train Loss: 0.4518113654426166 Train Acc: 0.8843428571428571 Val Loss: 0.674559320807457 Val Acc: 0.8068\n",
      "Epoch: 57 Train Loss: 0.4509982392617634 Train Acc: 0.8812 Val Loss: 0.680477443933487 Val Acc: 0.8084\n",
      "Epoch: 58 Train Loss: 0.4508029266340392 Train Acc: 0.8842857142857142 Val Loss: 0.6741489988565444 Val Acc: 0.8132\n",
      "Epoch: 59 Train Loss: 0.4449171847956521 Train Acc: 0.8868571428571429 Val Loss: 0.6738459551334381 Val Acc: 0.8076\n",
      "Epoch: 60 Train Loss: 0.4429351510320391 Train Acc: 0.8870285714285714 Val Loss: 0.6750404632091522 Val Acc: 0.8084\n",
      "Epoch: 61 Train Loss: 0.43835543687854495 Train Acc: 0.8866285714285714 Val Loss: 0.6745519000291824 Val Acc: 0.8068\n",
      "Epoch: 62 Train Loss: 0.43542083399636405 Train Acc: 0.8881714285714286 Val Loss: 0.6728534662723541 Val Acc: 0.808\n",
      "Epoch: 63 Train Loss: 0.4343588993379048 Train Acc: 0.8877714285714285 Val Loss: 0.6768348556756973 Val Acc: 0.8072\n",
      "Epoch: 64 Train Loss: 0.43112709667001453 Train Acc: 0.8891428571428571 Val Loss: 0.6798948079347611 Val Acc: 0.8088\n",
      "Epoch: 65 Train Loss: 0.43033288185085566 Train Acc: 0.8935428571428572 Val Loss: 0.6727250593900681 Val Acc: 0.8136\n",
      "Epoch: 66 Train Loss: 0.4282374729003225 Train Acc: 0.8923428571428571 Val Loss: 0.6693065464496613 Val Acc: 0.8096\n",
      "Epoch: 67 Train Loss: 0.42698905915021895 Train Acc: 0.8916571428571428 Val Loss: 0.671538143157959 Val Acc: 0.8088\n",
      "Epoch: 68 Train Loss: 0.4238766234261649 Train Acc: 0.8937714285714286 Val Loss: 0.6743547761440277 Val Acc: 0.8068\n",
      "Epoch: 69 Train Loss: 0.42295891442469186 Train Acc: 0.8938857142857143 Val Loss: 0.6729659193754196 Val Acc: 0.8088\n",
      "Epoch: 70 Train Loss: 0.4229062420129776 Train Acc: 0.8952571428571429 Val Loss: 0.6731094190478325 Val Acc: 0.8052\n",
      "Epoch: 71 Train Loss: 0.4167674423967089 Train Acc: 0.8947428571428572 Val Loss: 0.6702967447042465 Val Acc: 0.8096\n",
      "Epoch: 72 Train Loss: 0.4194200253060886 Train Acc: 0.8944571428571428 Val Loss: 0.6680879390239716 Val Acc: 0.8128\n",
      "Epoch: 73 Train Loss: 0.41887821444443296 Train Acc: 0.8959428571428572 Val Loss: 0.6689715570211411 Val Acc: 0.8096\n",
      "Epoch: 74 Train Loss: 0.41324319647891183 Train Acc: 0.8962857142857142 Val Loss: 0.6728839129209518 Val Acc: 0.8072\n",
      "Epoch: 75 Train Loss: 0.41191911403621945 Train Acc: 0.8985714285714286 Val Loss: 0.6690927916765212 Val Acc: 0.8096\n",
      "Epoch: 76 Train Loss: 0.4128167943443571 Train Acc: 0.8964 Val Loss: 0.6704267609119415 Val Acc: 0.8092\n",
      "Epoch: 77 Train Loss: 0.4125704136065074 Train Acc: 0.8966285714285714 Val Loss: 0.6704178071022033 Val Acc: 0.8124\n",
      "Epoch: 78 Train Loss: 0.40993544863803044 Train Acc: 0.8970285714285714 Val Loss: 0.6709741646051407 Val Acc: 0.8132\n",
      "Epoch: 79 Train Loss: 0.40727249609572547 Train Acc: 0.8988571428571429 Val Loss: 0.6676906919479371 Val Acc: 0.8132\n",
      "Epoch: 80 Train Loss: 0.4083906040447099 Train Acc: 0.8983428571428571 Val Loss: 0.6698675441741944 Val Acc: 0.8112\n",
      "Epoch: 81 Train Loss: 0.40821415190185817 Train Acc: 0.8995428571428571 Val Loss: 0.6669300609827041 Val Acc: 0.81\n",
      "Epoch: 82 Train Loss: 0.4069001841545105 Train Acc: 0.8999428571428572 Val Loss: 0.6675744360685348 Val Acc: 0.8108\n",
      "Epoch: 83 Train Loss: 0.4048242151311466 Train Acc: 0.9004571428571428 Val Loss: 0.6691037064790726 Val Acc: 0.8084\n",
      "Epoch: 84 Train Loss: 0.40269447573593686 Train Acc: 0.9009142857142857 Val Loss: 0.6691511470079422 Val Acc: 0.8132\n",
      "Epoch: 85 Train Loss: 0.4034512448310852 Train Acc: 0.8998857142857143 Val Loss: 0.6676365679502487 Val Acc: 0.8104\n",
      "Epoch: 86 Train Loss: 0.400381079018116 Train Acc: 0.9006285714285714 Val Loss: 0.6683596765995026 Val Acc: 0.8108\n",
      "Epoch: 87 Train Loss: 0.40086404208626064 Train Acc: 0.8998285714285714 Val Loss: 0.6684176743030548 Val Acc: 0.8096\n",
      "Epoch: 88 Train Loss: 0.40133165491478784 Train Acc: 0.9013714285714286 Val Loss: 0.6694940721988678 Val Acc: 0.8112\n",
      "Epoch: 89 Train Loss: 0.4014264558894294 Train Acc: 0.9009714285714285 Val Loss: 0.6692411512136459 Val Acc: 0.8128\n",
      "Epoch: 90 Train Loss: 0.40241673303501946 Train Acc: 0.9006285714285714 Val Loss: 0.6694344073534012 Val Acc: 0.8116\n"
     ]
    }
   ],
   "source": [
    "lr = .00022\n",
    "epochs = 100\n",
    "\n",
    "model = ImageClassifier()\n",
    "optim = torch.optim.Adam(model.parameters(), lr, weight_decay = .15)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma = .95)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_loss_per_epoch = []\n",
    "val_loss_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_acc = 0.\n",
    "    val_acc = 0.\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        inputs, labels = batch\n",
    "        inputs = torch.reshape(inputs, (batch_size, 1, 28, 28))\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.item())\n",
    "        prediction = torch.argmax(outputs, dim=1)\n",
    "        batch_acc = (prediction == labels).sum().item()\n",
    "        train_acc += batch_acc\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()  \n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():  \n",
    "            inputs, labels = batch\n",
    "            inputs = torch.reshape(inputs, (batch_size, 1, 28, 28))\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            prediction = torch.argmax(outputs, dim=1)\n",
    "            batch_acc = (prediction == labels).sum().item()\n",
    "            val_acc += batch_acc\n",
    "    train_acc /= len(train_dataloader.dataset)\n",
    "    val_acc /= len(val_dataloader.dataset)\n",
    "    print(\"Epoch:\", epoch, \"Train Loss:\", np.mean(train_loss), \"Train Acc:\", train_acc, \"Val Loss:\", np.mean(val_loss), \"Val Acc:\", val_acc)\n",
    "    train_loss_per_epoch.append(np.mean(train_loss))\n",
    "    val_loss_per_epoch.append(np.mean(val_loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575be74-d449-4178-8e52-4f142d618645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test set !!!\n",
    "correct = 0\n",
    "    \n",
    "model.eval()  \n",
    "for idx, batch in enumerate(test_dataloader):\n",
    "    with torch.no_grad():  \n",
    "        inputs, labels = batch\n",
    "        inputs = torch.reshape(inputs, (batch_size, 1, 28, 28))\n",
    "        outputs = model.forward(inputs)\n",
    "        prediction = torch.argmax(outputs, dim=1)\n",
    "        batch_correct = (prediction == labels).sum().item()\n",
    "        correct += batch_correct\n",
    "            \n",
    "print(\"Accuracy:\", correct/len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf7872-2f09-43c4-b3cb-06191b1f17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_per_epoch, label='Training Loss')\n",
    "plt.plot(val_loss_per_epoch, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 2])\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94061236-2acb-497e-b5e4-a385cb563ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = test_dataset[51]\n",
    "plt.imshow(input, cmap='gray')\n",
    "print(input)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()\n",
    "print(model.predict(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8352b-3f9e-465d-a9c8-43821d553608",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save('model_scripted.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
